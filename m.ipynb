{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries used in the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=pd.read_csv(\"train.csv\")\n",
    "t2=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the train and test files using the read function of the pandas   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the first five rows of the train dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the first five rows of the test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.shape,t2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the shape of the train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.info()\n",
    "#df[column].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the null values in the columns of the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dtype(t1[\"rez_esc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in t1.columns:\n",
    "    if np.dtype(t1[i]) in [\"float64\",\"int64\"]:\n",
    "        t1[i]=t1[i].fillna(value=t1[i].median())\n",
    "    if np.dtype(t1[i]) in [\"object\"]:\n",
    "        t1[i]=t1[i].fillna(value=t1[i].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the null values from the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output variable or the target variable is \"Target\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the null values in the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in t2.columns:\n",
    "    if np.dtype(t2[i]) in [\"float64\",\"int64\"]:\n",
    "        t2[i]=t2[i].fillna(value=t2[i].median())\n",
    "    if np.dtype(t1[i]) in [\"object\"]:\n",
    "        t2[i]=t2[i].fillna(value=t2[i].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the null values from the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the minimum and maximum values using the describe function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in t1.columns:\n",
    "    if np.dtype(t1[i]) in [\"float64\",\"int64\"]: \n",
    "        plt.figure()\n",
    "        t1[i].plot(kind='box',figsize=(7,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the boxplot for the different columns in the train dataset.In the boxplot of all the columns the value is greater then 0 then we need not to remove the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = t1[\"Target\"]\n",
    "print(np.unique(labels.values))\n",
    "fig, ax = plot.subplots()\n",
    "(labels.value_counts()).plot(ax=ax, kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the bar graph for the \"Target\" column in the train dataset that will represent the different bars of the unique values in the target column and also provide the count for the number of unique values in the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "for i in t1.columns.drop([\"dependency\",\"Target\"]):\n",
    "    t1[i]=le.fit_transform(t1[i])\n",
    "t1.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the label encoding is performed in the train dataset that will encode each of the column present in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1[\"dependency\"]=t1[\"dependency\"].replace(to_replace=\"yes\",value=1)\n",
    "t1[\"dependency\"]=t1[\"dependency\"].replace(to_replace=\"no\",value=0)\n",
    "#t1[\"dependency\"]=t1[\"dependency\"].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this we have replaced the value of yes with 1 and the value of no withe 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the info() we have checked that all the columns are now converted in the int64 datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "f=t1.columns.drop(\"Target\")\n",
    "s_values=scaler.fit_transform(t1[f])\n",
    "a=0\n",
    "for i in f:\n",
    "    t1[i]=s_values[:,a]\n",
    "    a+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are using the MinMaxScaler function to normalize all the columns present in the train dataset leaving the target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=20)\n",
    "features=t1.columns.drop(\"Target\")\n",
    "X=pca.fit_transform(t1[features])\n",
    "X.shape\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this we are using the PCA technique for the feature engineering that will provide us the important columns that have high variance as compared to the remaining columns present in the dataset.In this we are selecting 10 columns from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1=PCA(0.95)\n",
    "pc1.fit_transform(t1[features]).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used to check that how many columns we have to take that will provideus the 95% variation for the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=pd.DataFrame(X,columns=['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t'])\n",
    "q['Target']=t1['Target']\n",
    "q.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here q dataframe is created which has the 10 columns that have the high variance which we get from the PCA technique and also a target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This columns() function returns the name of the columns present in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train,test = train_test_split(q,test_size=0.10,random_state=100)\n",
    "features = train.columns.drop(\"Target\")\n",
    "target = [\"Target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this train_test_split function is used to split the train dataset into two parts train and test.The train part will be used to train the model and test part will be used to test or validate the performance of the model.90% data is given for tarining and 10% data is given for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=15,min_samples_split=25,min_impurity_decrease=0.15)\n",
    "model.fit(train[features],train[target])\n",
    "train_accuracy = model.score(train[features],train[target])\n",
    "test_accuracy = model.score(test[features],test[target])\n",
    "print(train_accuracy,test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this the random forest classifier model has been prepared and then the model is trained using the dataset which is separated for the training purpose and then the accuracy of the model hs been tested using the dataset which is seperated for the testing purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "k_fold = KFold(n_splits=5,shuffle=False,random_state=100)\n",
    "features = train.columns.drop(\"Target\")\n",
    "target = [\"Target\"]\n",
    "knn_k_vals = [1,3,5,7,9,11]\n",
    "avg_train_accuracy = []\n",
    "avg_val_accuracy = []\n",
    "X = train[features]\n",
    "y = train[target]\n",
    "for k in knn_k_vals: \n",
    "    train_accuracy = []\n",
    "    val_accuracy = []\n",
    "    for i,(train,val) in enumerate(k_fold.split(X,y)): \n",
    "        model = KNeighborsClassifier(n_neighbors=k,metric=\"euclidean\")\n",
    "        model.fit(X.iloc[train],y.iloc[train])\n",
    "        train_accuracy.append(model.score(X.iloc[train],y.iloc[train]))\n",
    "        val_accuracy.append(model.score(X.iloc[val],y.iloc[val]))\n",
    "    avg_train_accuracy.append(np.mean(train_accuracy))\n",
    "    avg_val_accuracy.append(np.mean(val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_scores = pd.DataFrame(np.array([knn_k_vals,avg_train_accuracy,avg_val_accuracy]).T,columns=[\"k\",\"avg_train_accuracy\",\"avg_val_accuracy\"])\n",
    "performance_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = performance_scores[\"k\"][performance_scores[\"avg_val_accuracy\"]==\n",
    "                                 performance_scores[\"avg_val_accuracy\"].max()]\n",
    "best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the help of this cross validation technique we will get the value of the n_neighours that at which value of n_neighbour the model is more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors = 9, metric=\"euclidean\")\n",
    "model.fit(X,y)\n",
    "train_accuracy = model.score(X,y)\n",
    "test_accuracy = model.score(test[features],test[target])\n",
    "print(train_accuracy,test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
